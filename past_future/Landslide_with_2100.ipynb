{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N6_ACJ418SA"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Drive einbinden\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project= 'deepalpine')\n",
        "\n",
        "input_path = '/content/drive/MyDrive/testNaturgefahren/landslides_WITH_NEW_RAIN.csv'\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "output_path = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "\n",
        "print(f\"Datei geladen. Erstelle jetzt Vorhersagen für {len(df)} Punkte...\")\n",
        "\n",
        "# 3. Speichern als neue Datei\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"Fertig! Die neue Datei wurde hier gespeichert: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "from google.colab import drive\n",
        "\n",
        "# Drive einbinden\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Pfade definieren\n",
        "url = \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp126/wc2.1_30s_prec_MPI-ESM1-2-HR_ssp126_2081-2100.tif\"\n",
        "local_tif = \"/content/global_data.tif\"\n",
        "save_path = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_2100_1km'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# Südtirol Bounding Box\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "# 1. Download der TIF-Datei\n",
        "print(\"Starte Download der TIF-Datei... Bitte warten.\")\n",
        "# -O speichert es unter dem definierten Namen\n",
        "os.system(f\"wget -c {url} -O {local_tif}\")\n",
        "\n",
        "# 2. Prüfen, ob der Download erfolgreich war\n",
        "if os.path.exists(local_tif) and os.path.getsize(local_tif) > 0:\n",
        "    print(f\"Download fertig ({os.path.getsize(local_tif) / 1024**3:.2f} GB). Beginne mit dem Zuschneiden.\")\n",
        "\n",
        "    with rasterio.open(local_tif) as src:\n",
        "        bands = src.count\n",
        "        print(f\"Datei hat {bands} Bänder (Monate).\")\n",
        "\n",
        "        for i in range(1, bands + 1):\n",
        "            out_image, out_transform = mask(src, geo.geometry, crop=True, indexes=i)\n",
        "\n",
        "            # Metadaten für die kleine Datei vorbereiten\n",
        "            out_meta = src.meta.copy()\n",
        "            out_meta.update({\n",
        "                \"driver\": \"GTiff\",\n",
        "                \"height\": out_image.shape[1],\n",
        "                \"width\": out_image.shape[2],\n",
        "                \"transform\": out_transform,\n",
        "                \"count\": 1 # Nur ein Band pro Monatsspeicherung\n",
        "            })\n",
        "\n",
        "            output_filename = f\"{save_path}/prec_2100_month_{i:02d}.tif\"\n",
        "            with rasterio.open(output_filename, \"w\", **out_meta) as dest:\n",
        "                dest.write(out_image)\n",
        "            print(f\"Monat {i} für Südtirol gespeichert.\")\n",
        "\n",
        "    os.remove(local_tif)\n",
        "    print(\"\\n fertig gelöscht\")\n",
        "else:\n",
        "    print(\"Fehler: Die Datei konnte nicht geladen werden oder ist leer.\")"
      ],
      "metadata": {
        "id": "-xz3rcMV_di1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "local_tif = \"/content/global_data.tif\"\n",
        "save_path = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_2100_1km'\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# Bounding Box für Südtirol\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "# Öffne die bereits heruntergeladene Datei\n",
        "if os.path.exists(local_tif):\n",
        "    with rasterio.open(local_tif) as src:\n",
        "        print(f\"Starte Zuschnitt für {src.count} Monate (Bänder)...\")\n",
        "\n",
        "        # Alle Bänder gleichzeitig zuschneiden (erzeugt 3D-Array: Bänder, Höhe, Breite)\n",
        "        out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "\n",
        "        # Grundgerüst für Metadaten kopieren\n",
        "        out_meta = src.meta.copy()\n",
        "\n",
        "        for i in range(1, src.count + 1):\n",
        "            # Index i-1 für den Zugriff auf das Array\n",
        "            band_data = out_image[i-1]\n",
        "\n",
        "            # Metadaten für die einzelne Datei aktualisieren\n",
        "            # band_data ist 2D, daher shape[0]=Höhe, shape[1]=Breite\n",
        "            out_meta.update({\n",
        "                \"driver\": \"GTiff\",\n",
        "                \"height\": band_data.shape[0],\n",
        "                \"width\": band_data.shape[1],\n",
        "                \"transform\": out_transform,\n",
        "                \"count\": 1\n",
        "            })\n",
        "\n",
        "            output_filename = f\"{save_path}/prec_2100_month_{i:02d}.tif\"\n",
        "\n",
        "            # Monatsspezifische Datei schreiben\n",
        "            with rasterio.open(output_filename, \"w\", **out_meta) as dest:\n",
        "                dest.write(band_data, 1)\n",
        "\n",
        "            print(f\"Monat {i} erfolgreich in Südtirol-Ordner gespeichert.\")\n",
        "\n",
        "    # Lokale Datei nach Erfolg löschen\n",
        "    os.remove(local_tif)\n",
        "    print(\"erfolgreich gelöscht\")\n",
        "else:\n",
        "    print(\"Fehler\")"
      ],
      "metadata": {
        "id": "d1Ms_oEnDHs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import rasterio\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "tiff_folder = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_2100_1km'\n",
        "\n",
        "# CSV laden\n",
        "if not os.path.exists(csv_path):\n",
        "    print(\"Fehler: CSV-Datei nicht gefunden!\")\n",
        "else:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Lese Daten für {len(df)} Punkte...\")\n",
        "\n",
        "    # 2. Durch alle 12 Monate iterieren\n",
        "    for month in range(1, 13):\n",
        "        # Dateinamen konstruieren\n",
        "        tif_file = f\"{tiff_folder}/prec_2100_month_{month:02d}.tif\"\n",
        "        col_name = f\"Prec_2100_SSP126_M{month:02d}\"\n",
        "\n",
        "        if os.path.exists(tif_file):\n",
        "            with rasterio.open(tif_file) as src:\n",
        "                # Koordinaten-Liste erstellen (Longitude, Latitude)\n",
        "                coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "\n",
        "                # Werte auslesen (sample gibt einen Generator zurück)\n",
        "                # Wir nehmen den ersten Wert [0], da wir nur ein Band pro Datei haben\n",
        "                values = [val[0] for val in src.sample(coords)]\n",
        "\n",
        "                # In den DataFrame schreiben\n",
        "                df[col_name] = values\n",
        "                print(f\"Monat {month:02d}: Daten extrahiert.\")\n",
        "        else:\n",
        "            print(f\"Datei für Monat {month} nicht gefunden: {tif_file}\")\n",
        "\n",
        "    # 3. Speichern\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"\\nFertig! Die Datei wurde aktualisiert: {csv_path}\")\n",
        "    print(\"CSV enthält jetzt 12 neue Spalten mit den monatlichen Regenmengen für 2100\")"
      ],
      "metadata": {
        "id": "Y-hIxEUSDaLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_path = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_2100_SSP585_1km'\n",
        "local_tif = \"/content/global_data_ssp585.tif\"\n",
        "url = \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp585/wc2.1_30s_prec_MPI-ESM1-2-HR_ssp585_2081-2100.tif\"\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# Bounding Box für Südtirol\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "# 1. Download\n",
        "print(\"Starte Download für SSP585 (ca. 21 GB)... Bitte Tab offen lassen.\")\n",
        "if not os.path.exists(local_tif):\n",
        "    os.system(f\"wget -c {url} -O {local_tif}\")\n",
        "\n",
        "# 2. Zuschneiden\n",
        "if os.path.exists(local_tif) and os.path.getsize(local_tif) > 1000:\n",
        "    print(\"Download erfolgreich. Starte Zuschnitt...\")\n",
        "\n",
        "    with rasterio.open(local_tif) as src:\n",
        "        # Alle 12 Bänder (Monate) auf einmal maskieren\n",
        "        out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "        out_meta = src.meta.copy()\n",
        "\n",
        "        for i in range(1, src.count + 1):\n",
        "            band_data = out_image[i-1]\n",
        "\n",
        "            out_meta.update({\n",
        "                \"driver\": \"GTiff\",\n",
        "                \"height\": band_data.shape[0],\n",
        "                \"width\": band_data.shape[1],\n",
        "                \"transform\": out_transform,\n",
        "                \"count\": 1\n",
        "            })\n",
        "\n",
        "            # Dateiname explizit mit 'ssp585' kennzeichnen\n",
        "            output_filename = f\"{save_path}/prec_2100_ssp585_month_{i:02d}.tif\"\n",
        "\n",
        "            with rasterio.open(output_filename, \"w\", **out_meta) as dest:\n",
        "                dest.write(band_data, 1)\n",
        "            print(f\"Monat {i} (SSP585) gespeichert.\")\n",
        "\n",
        "    # Aufräumen\n",
        "    os.remove(local_tif)\n",
        "    print(\"SSP585 VERARBEITUNG ABGESCHLOSSEN\")\n",
        "else:\n",
        "    print(\"Fehler beim Download\")"
      ],
      "metadata": {
        "id": "uj28OsMLEhul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import rasterio\n",
        "import os\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "tiff_folder = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_2100_SSP585_1km'\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Lese SSP585-Werte für {len(df)} Punkte...\")\n",
        "\n",
        "    for month in range(1, 13):\n",
        "        tif_file = f\"{tiff_folder}/prec_2100_ssp585_month_{month:02d}.tif\"\n",
        "        col_name = f\"Prec_2100_SSP585_M{month:02d}\"\n",
        "\n",
        "        if os.path.exists(tif_file):\n",
        "            with rasterio.open(tif_file) as src:\n",
        "                coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "                # Werte auslesen\n",
        "                df[col_name] = [val[0] for val in src.sample(coords)]\n",
        "                print(f\"Monat {month:02d} hinzugefügt.\")\n",
        "        else:\n",
        "            print(f\"Warnung: Datei für Monat {month} fehlt.\")\n",
        "\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(\"Fertig! CSV enthält jetzt beide Szenarien (SSP126 und SSP585).\")"
      ],
      "metadata": {
        "id": "0S7l59dbHHkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(\"Berechne Bioklimatische Variablen für\", len(df), \"Punkte...\")\n",
        "\n",
        "def calculate_bio_precip(row, scenario_prefix):\n",
        "    \"\"\"\n",
        "    Berechnet BIO12, BIO13 und BIO15 für ein gegebenes Szenario.\n",
        "    \"\"\"\n",
        "    # 1. Die 12 Monatswerte\n",
        "    cols = [f\"{scenario_prefix}_M{i:02d}\" for i in range(1, 13)]\n",
        "\n",
        "    # Existieren die Spalten?\n",
        "    if not all(col in row.index for col in cols):\n",
        "        return pd.Series([0, 0, 0])\n",
        "\n",
        "    values = row[cols].values.astype(float)\n",
        "\n",
        "    # 2. Berechnung\n",
        "    bio12 = np.sum(values)           # Jahresniederschlag (Summe)\n",
        "    bio13 = np.max(values)           # Nassester Monat (Maximum)\n",
        "\n",
        "    # Saisonalität (Variationskoeffizient)\n",
        "    # Formel: (Standardabweichung / Mittelwert) * 100\n",
        "    mean_val = np.mean(values)\n",
        "    if mean_val > 0:\n",
        "        bio15 = (np.std(values) / mean_val) * 100\n",
        "    else:\n",
        "        bio15 = 0\n",
        "\n",
        "    return pd.Series([round(bio12, 1), round(bio13, 1), round(bio15, 1)])\n",
        "\n",
        "# Berechnung für SSP126\n",
        "print(\"Verarbeite SSP126...\")\n",
        "new_cols_126 = df.apply(lambda row: calculate_bio_precip(row, \"Prec_2100_SSP126\"), axis=1)\n",
        "new_cols_126.columns = ['BIO12_2100_SSP126', 'BIO13_2100_SSP126', 'BIO15_2100_SSP126']\n",
        "df = pd.concat([df, new_cols_126], axis=1)\n",
        "\n",
        "# Berechnung für SSP585\n",
        "print(\"Verarbeite SSP585...\")\n",
        "new_cols_585 = df.apply(lambda row: calculate_bio_precip(row, \"Prec_2100_SSP585\"), axis=1)\n",
        "new_cols_585.columns = ['BIO12_2100_SSP585', 'BIO13_2100_SSP585', 'BIO15_2100_SSP585']\n",
        "df = pd.concat([df, new_cols_585], axis=1)\n",
        "\n",
        "# Speichern\n",
        "df.to_csv(csv_path, index=False)\n",
        "print(\"\\nFertig!\")\n",
        "print(\"Beispiel für den ersten Punkt:\")\n",
        "print(df[['BIO12_2100_SSP126', 'BIO12_2100_SSP585']].head(1))"
      ],
      "metadata": {
        "id": "gTkYgUIII7p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_WITH_NEW_RAIN.csv'\n",
        "# neue Datei für das Training:\n",
        "output_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_COMPLETE.csv'\n",
        "\n",
        "# Ordner für die Karten\n",
        "save_folder = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_Historical_Bio'\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)\n",
        "\n",
        "# Bounding Box Südtirol\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "# DOWNLOAD\n",
        "# Das ist der Link für \"Bioclimatic variables\" (enthält Regen UND Temperatur)\n",
        "# Auflösung: 30 seconds (ca. 1 km)\n",
        "url = \"https://geodata.ucdavis.edu/climate/worldclim/2_1/base/wc2.1_30s_bio.zip\"\n",
        "zip_file = \"/content/worldclim_bio_historical.zip\"\n",
        "\n",
        "print(\"1. Lade historische WorldClim-Daten (Regen & Temp)...\")\n",
        "if not os.path.exists(zip_file):\n",
        "    os.system(f\"wget -q --show-progress -c {url} -O {zip_file}\")\n",
        "else:\n",
        "    print(\"ZIP-Datei ist schon da (spart Zeit).\")\n",
        "\n",
        "# EXTRAKTION\n",
        "# BIO1 = Jahresdurchschnittstemperatur\n",
        "# BIO12 = Jahresniederschlag\n",
        "# BIO13 = Niederschlag des nassesten Monats\n",
        "# BIO15 = Saisonalität (Variation)\n",
        "target_files = {\n",
        "    'wc2.1_30s_bio_01.tif': 'BIO01_Historical_Temp',\n",
        "    'wc2.1_30s_bio_12.tif': 'BIO12_Historical_Prec',\n",
        "    'wc2.1_30s_bio_13.tif': 'BIO13_Historical_Prec',\n",
        "    'wc2.1_30s_bio_15.tif': 'BIO15_Historical_Prec'\n",
        "}\n",
        "\n",
        "print(\"2. Schneide Südtirol aus den Weltkarten...\")\n",
        "\n",
        "final_tifs = {}\n",
        "\n",
        "with zipfile.ZipFile(zip_file, 'r') as z:\n",
        "    for original_name, new_col_name in target_files.items():\n",
        "        # Datei aus ZIP holen\n",
        "        z.extract(original_name, path=\"/content/temp_extract\")\n",
        "        input_path = f\"/content/temp_extract/{original_name}\"\n",
        "        output_path = f\"{save_folder}/{new_col_name}.tif\"\n",
        "\n",
        "        # Zuschneiden\n",
        "        with rasterio.open(input_path) as src:\n",
        "            out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "            out_meta = src.meta.copy()\n",
        "            out_meta.update({\n",
        "                \"driver\": \"GTiff\",\n",
        "                \"height\": out_image.shape[1],\n",
        "                \"width\": out_image.shape[2],\n",
        "                \"transform\": out_transform\n",
        "            })\n",
        "            with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
        "                dest.write(out_image)\n",
        "\n",
        "        final_tifs[new_col_name] = output_path\n",
        "        # Temporäre Datei löschen\n",
        "        os.remove(input_path)\n",
        "        print(f\"  -> {new_col_name} bereit.\")\n",
        "\n",
        "# WERTE IN NEUE CSV SCHREIBEN\n",
        "print(\"3. Erstelle die finale Trainingsdatei...\")\n",
        "\n",
        "if os.path.exists(input_csv):\n",
        "    df = pd.read_csv(input_csv)\n",
        "    print(f\"Lese {len(df)} Zeilen ein...\")\n",
        "\n",
        "    # Koordinaten\n",
        "    coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "\n",
        "    for col_name, tif_path in final_tifs.items():\n",
        "        with rasterio.open(tif_path) as src:\n",
        "            # Werte auslesen\n",
        "            values = [x[0] for x in src.sample(coords)]\n",
        "            df[col_name] = values\n",
        "            print(f\"  + Spalte '{col_name}' hinzugefügt.\")\n",
        "\n",
        "    # Speichern als neue Datei\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"FERTIG!\")\n",
        "    print(f\"{output_csv}\")\n",
        "    print(\"Diese Datei enthält jetzt:\")\n",
        "    print(\"- Die alten Regendaten (7d, 14d...)\")\n",
        "    print(\"- Historische Temperatur (BIO1)\")\n",
        "    print(\"- Historische Niederschlags-Trends (BIO12, 13, 15)\")\n",
        "else:\n",
        "    print(\"fehler\")"
      ],
      "metadata": {
        "id": "cuNYiFVvNWSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_WITH_NEW_RAIN.csv'\n",
        "output_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_COMPLETE.csv'\n",
        "save_folder = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_Historical_Bio'\n",
        "zip_file = \"/content/worldclim_bio_historical.zip\"\n",
        "\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)\n",
        "\n",
        "# Bounding Box\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "target_files = {\n",
        "    'wc2.1_30s_bio_1.tif': 'BIO01_Historical_Temp',\n",
        "    'wc2.1_30s_bio_12.tif': 'BIO12_Historical_Prec',\n",
        "    'wc2.1_30s_bio_13.tif': 'BIO13_Historical_Prec',\n",
        "    'wc2.1_30s_bio_15.tif': 'BIO15_Historical_Prec'\n",
        "}\n",
        "\n",
        "print(\"Prüfe ZIP-Inhalt und starte Extraktion...\")\n",
        "\n",
        "if os.path.exists(zip_file):\n",
        "    final_tifs = {}\n",
        "\n",
        "    with zipfile.ZipFile(zip_file, 'r') as z:\n",
        "        all_files = z.namelist()\n",
        "\n",
        "        for original_name, new_col_name in target_files.items():\n",
        "            if original_name in all_files:\n",
        "                # Datei extrahieren\n",
        "                z.extract(original_name, path=\"/content/temp_extract\")\n",
        "                input_path = f\"/content/temp_extract/{original_name}\"\n",
        "                output_path = f\"{save_folder}/{new_col_name}.tif\"\n",
        "\n",
        "                # Zuschneiden\n",
        "                with rasterio.open(input_path) as src:\n",
        "                    out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "                    out_meta = src.meta.copy()\n",
        "                    out_meta.update({\n",
        "                        \"driver\": \"GTiff\",\n",
        "                        \"height\": out_image.shape[1],\n",
        "                        \"width\": out_image.shape[2],\n",
        "                        \"transform\": out_transform\n",
        "                    })\n",
        "                    with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
        "                        dest.write(out_image)\n",
        "\n",
        "                final_tifs[new_col_name] = output_path\n",
        "                os.remove(input_path)\n",
        "                print(f\"  -> {new_col_name} erfolgreich erstellt.\")\n",
        "            else:\n",
        "                print(f\"WARNUNG: Konnte {original_name} nicht im ZIP finden. Die Datei heißt im ZIP wohl anders.\")\n",
        "                similar = [f for f in all_files if \"bio\" in f and \"tif\" in f]\n",
        "                print(f\"  Verfügbare Dateien sind: {similar[:5]}...\")\n",
        "\n",
        "    if os.path.exists(input_csv):\n",
        "        print(\"\\nSchreibe Daten in die neue CSV...\")\n",
        "        df = pd.read_csv(input_csv)\n",
        "        coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "\n",
        "        for col_name, tif_path in final_tifs.items():\n",
        "            with rasterio.open(tif_path) as src:\n",
        "                values = [x[0] for x in src.sample(coords)]\n",
        "                df[col_name] = values\n",
        "                print(f\"  + Spalte '{col_name}' eingetragen.\")\n",
        "\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"\\nFERTIG! Neue Datei erstellt: {output_csv}\")\n",
        "    else:\n",
        "        print(\"Fehler: Eingabe-CSV fehlt.\")\n",
        "else:\n",
        "    print(\"Fehler: ZIP-Datei nicht gefunden.\")"
      ],
      "metadata": {
        "id": "4X-LhJYDPnp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "input_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_WITH_NEW_RAIN.csv'\n",
        "output_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_COMPLETE.csv'\n",
        "save_folder = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_Historical_Bio'\n",
        "zip_file = \"/content/worldclim_bio_historical.zip\"\n",
        "\n",
        "if not os.path.exists(save_folder):\n",
        "    os.makedirs(save_folder)\n",
        "\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "target_files = {\n",
        "    'wc2.1_30s_bio_1.tif': 'BIO01_Historical_Mean',  # Durchschnitt\n",
        "    'wc2.1_30s_bio_5.tif': 'BIO05_Historical_Max',   # Wärmster Monat\n",
        "    'wc2.1_30s_bio_6.tif': 'BIO06_Historical_Min',   # Kältester Monat\n",
        "    'wc2.1_30s_bio_12.tif': 'BIO12_Historical_Prec', # Jahresregen\n",
        "    'wc2.1_30s_bio_13.tif': 'BIO13_Historical_Prec', # Nassester Monat\n",
        "    'wc2.1_30s_bio_15.tif': 'BIO15_Historical_Prec'  # Saisonalität\n",
        "}\n",
        "\n",
        "print(\"1. Extrahiere Historische Daten (inkl. Sommer/Winter-Extreme)...\")\n",
        "\n",
        "# Falls ZIP nicht da, lade es\n",
        "url = \"https://geodata.ucdavis.edu/climate/worldclim/2_1/base/wc2.1_30s_bio.zip\"\n",
        "if not os.path.exists(zip_file):\n",
        "    os.system(f\"wget -q -c {url} -O {zip_file}\")\n",
        "\n",
        "final_tifs = {}\n",
        "\n",
        "with zipfile.ZipFile(zip_file, 'r') as z:\n",
        "    all_files = z.namelist()\n",
        "    for original_name, new_col_name in target_files.items():\n",
        "        if original_name in all_files:\n",
        "            z.extract(original_name, path=\"/content/temp_extract\")\n",
        "            input_path = f\"/content/temp_extract/{original_name}\"\n",
        "            output_path = f\"{save_folder}/{new_col_name}.tif\"\n",
        "\n",
        "            with rasterio.open(input_path) as src:\n",
        "                out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "                out_meta = src.meta.copy()\n",
        "                out_meta.update({\"driver\": \"GTiff\", \"height\": out_image.shape[1], \"width\": out_image.shape[2], \"transform\": out_transform})\n",
        "                with rasterio.open(output_path, \"w\", **out_meta) as dest:\n",
        "                    dest.write(out_image)\n",
        "\n",
        "            final_tifs[new_col_name] = output_path\n",
        "            os.remove(input_path)\n",
        "            print(f\"  -> {new_col_name} erstellt.\")\n",
        "\n",
        "print(\"2. Erstelle neue Trainings-CSV...\")\n",
        "\n",
        "if os.path.exists(input_csv):\n",
        "    df = pd.read_csv(input_csv)\n",
        "    coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "\n",
        "    for col_name, tif_path in final_tifs.items():\n",
        "        with rasterio.open(tif_path) as src:\n",
        "            values = [x[0] for x in src.sample(coords)]\n",
        "            df[col_name] = values\n",
        "            print(f\"  + {col_name} hinzugefügt.\")\n",
        "\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"\\nFERTIG!\")"
      ],
      "metadata": {
        "id": "BZ4_Qtx7Rn7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "save_folder = '/content/drive/MyDrive/testNaturgefahren/Suedtirol_2100_Temp'\n",
        "\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "urls = {\n",
        "    \"SSP126\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp126/wc2.1_30s_bio_MPI-ESM1-2-HR_ssp126_2081-2100.zip\",\n",
        "    \"SSP585\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp585/wc2.1_30s_bio_MPI-ESM1-2-HR_ssp585_2081-2100.zip\"\n",
        "}\n",
        "\n",
        "# BIO1 = Durchschnitt, BIO5 = Max Wärmster Monat, BIO6 = Min Kältester Monat\n",
        "target_vars = {\n",
        "    '01.tif': 'BIO01',\n",
        "    '05.tif': 'BIO05',\n",
        "    '06.tif': 'BIO06'\n",
        "}\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "\n",
        "    print(\"Aktualisiere Zukunftsszenarien mit saisonalen Temperaturen...\")\n",
        "\n",
        "    for scenario, url in urls.items():\n",
        "        zip_name = f\"/content/temp_{scenario}.zip\"\n",
        "\n",
        "        # Download (falls nicht da)\n",
        "        if not os.path.exists(zip_name):\n",
        "            print(f\"  Lade {scenario}...\")\n",
        "            os.system(f\"wget -q -c {url} -O {zip_name}\")\n",
        "\n",
        "        with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "            file_list = z.namelist()\n",
        "\n",
        "            for suffix, var_name in target_vars.items():\n",
        "                # Suche Datei, die auf z.B. '05.tif' endet\n",
        "                found_file = next((f for f in file_list if f.endswith(suffix)), None)\n",
        "\n",
        "                if found_file:\n",
        "                    z.extract(found_file, path=\"/content/temp_extract\")\n",
        "                    input_tif = f\"/content/temp_extract/{found_file}\"\n",
        "\n",
        "                    # Spaltenname z.B. BIO05_2100_SSP126\n",
        "                    if var_name == 'BIO01':\n",
        "                        final_col = f\"{var_name}_2100_{scenario}_Mean\"\n",
        "                    elif var_name == 'BIO05':\n",
        "                        final_col = f\"{var_name}_2100_{scenario}_Max\"\n",
        "                    elif var_name == 'BIO06':\n",
        "                        final_col = f\"{var_name}_2100_{scenario}_Min\"\n",
        "\n",
        "                    with rasterio.open(input_tif) as src:\n",
        "                        out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "\n",
        "                        # Metadaten für Memory-File\n",
        "                        out_meta = src.meta.copy()\n",
        "                        out_meta.update({\"driver\": \"GTiff\", \"height\": out_image.shape[1], \"width\": out_image.shape[2], \"transform\": out_transform})\n",
        "\n",
        "                        # Temporäres TIF speichern\n",
        "                        temp_small = f\"/content/small_{var_name}.tif\"\n",
        "                        with rasterio.open(temp_small, \"w\", **out_meta) as dest:\n",
        "                            dest.write(out_image)\n",
        "\n",
        "                        # Jetzt Werte holen\n",
        "                        with rasterio.open(temp_small) as small_src:\n",
        "                            df[final_col] = [x[0] for x in small_src.sample(coords)]\n",
        "                            print(f\"    + {final_col} eingetragen.\")\n",
        "\n",
        "                    # Aufräumen\n",
        "                    os.remove(input_tif)\n",
        "                else:\n",
        "                    print(f\"WARNUNG: {var_name} in {scenario} nicht gefunden!\")\n",
        "\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(\"fertig; Durchschnitt, Sommer-Max und Winter-Min für 2100\")\n",
        "\n",
        "else:\n",
        "    print(\"fehler\")"
      ],
      "metadata": {
        "id": "M__ZxnMcSgXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "temp_folder = '/content/temp_download' # Lokaler Temp-Ordner in Colab (schnell)\n",
        "\n",
        "if not os.path.exists(temp_folder):\n",
        "    os.makedirs(temp_folder)\n",
        "\n",
        "# Bounding Box Südtirol\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "# Links zu den Modelldaten (MPI-ESM1-2-HR, 30 seconds resolution)\n",
        "urls = {\n",
        "    \"SSP126\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp126/wc2.1_30s_bio_MPI-ESM1-2-HR_ssp126_2081-2100.zip\",\n",
        "    \"SSP585\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp585/wc2.1_30s_bio_MPI-ESM1-2-HR_ssp585_2081-2100.zip\"\n",
        "}\n",
        "\n",
        "# Durchschnitt (1), Max Sommer (5), Min Winter (6)\n",
        "target_vars = {\n",
        "    '01.tif': 'BIO01',\n",
        "    '05.tif': 'BIO05',\n",
        "    '06.tif': 'BIO06'\n",
        "}\n",
        "\n",
        "# weil vorher Download nicht funktioniert hat hat Gemini das gesagt, glaube nicht dass es daran lag aber ok\n",
        "def smart_download(url, dest_path):\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "    print(f\"Starte Download von {os.path.basename(url)}...\")\n",
        "    try:\n",
        "        with requests.get(url, stream=True, headers=headers, timeout=60) as r:\n",
        "            r.raise_for_status() # Fehler werfen, wenn Server blockt (403/404)\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "\n",
        "            with open(dest_path, 'wb') as f:\n",
        "                downloaded = 0\n",
        "                for chunk in r.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "                    downloaded += len(chunk)\n",
        "                    # Einfacher Fortschritts-Indikator alle 100MB\n",
        "                    if downloaded % (100 * 1024 * 1024) < 9000:\n",
        "                        print(f\"  ... {downloaded / (1024**3):.2f} GB geladen\", end='\\r')\n",
        "        print(f\"Download fertig.\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"feehler beim Download: {e}\")\n",
        "        return False\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "    print(f\"Verarbeite {len(df)} Punkte für echte Zukunftsdaten...\")\n",
        "\n",
        "    for scenario, url in urls.items():\n",
        "        zip_name = os.path.join(temp_folder, f\"{scenario}.zip\")\n",
        "\n",
        "        # 1. Download\n",
        "        if not os.path.exists(zip_name):\n",
        "            success = smart_download(url, zip_name)\n",
        "            if not success:\n",
        "                print(f\"Überspringe {scenario} wegen Download-Fehler.\")\n",
        "                continue\n",
        "\n",
        "        # 2. Prüfen ob ZIP okay ist\n",
        "        try:\n",
        "            with zipfile.ZipFile(zip_name, 'r') as z:\n",
        "                file_list = z.namelist()\n",
        "                print(f\"Entpacke relevante Daten für {scenario}...\")\n",
        "\n",
        "                for suffix, var_name in target_vars.items():\n",
        "                    # Suche die Datei (endet auf 01.tif, 05.tif usw.)\n",
        "                    found_file = next((f for f in file_list if f.endswith(suffix)), None)\n",
        "\n",
        "                    if found_file:\n",
        "                        # Extrahiere nur diese eine Datei\n",
        "                        z.extract(found_file, path=temp_folder)\n",
        "                        input_tif = os.path.join(temp_folder, found_file)\n",
        "\n",
        "                        # Spaltenname (z.B. BIO05_2100_SSP126_Max)\n",
        "                        col_suffix = \"_Mean\" if var_name == 'BIO01' else \"_Max\" if var_name == 'BIO05' else \"_Min\"\n",
        "                        final_col = f\"{var_name}_2100_{scenario}{col_suffix}\"\n",
        "\n",
        "                        # Zuschneiden & Lesen\n",
        "                        with rasterio.open(input_tif) as src:\n",
        "                            out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "\n",
        "                            # Temporäres kleines TIF\n",
        "                            small_tif = os.path.join(temp_folder, f\"small_{var_name}.tif\")\n",
        "                            out_meta = src.meta.copy()\n",
        "                            out_meta.update({\"driver\": \"GTiff\", \"height\": out_image.shape[1], \"width\": out_image.shape[2], \"transform\": out_transform})\n",
        "\n",
        "                            with rasterio.open(small_tif, \"w\", **out_meta) as dest:\n",
        "                                dest.write(out_image)\n",
        "\n",
        "                            # Werte sampeln\n",
        "                            with rasterio.open(small_tif) as small_src:\n",
        "                                vals = [x[0] for x in small_src.sample(coords)]\n",
        "                                df[final_col] = vals\n",
        "                                print(f\"  -> {final_col} erfolgreich ausgelesen.\")\n",
        "\n",
        "                        # Aufräumen\n",
        "                        if os.path.exists(input_tif): os.remove(input_tif)\n",
        "                        if os.path.exists(small_tif): os.remove(small_tif)\n",
        "                    else:\n",
        "                        print(f\"WARNUNG: {var_name} nicht im ZIP gefunden.\")\n",
        "\n",
        "            # Nach Erfolg das ZIP löschen, um Platz für das nächste Szenario zu machen\n",
        "            os.remove(zip_name)\n",
        "            print(f\"ZIP für {scenario} gelöscht (Speicherplatz freigegeben).\")\n",
        "\n",
        "        except zipfile.BadZipFile:\n",
        "            print(f\"CRITICAL: Die Datei für {scenario} ist trotz Browser-Trick beschädigt.\")\n",
        "            print(\"Der Server bricht vermutlich die Verbindung ab.\")\n",
        "\n",
        "    # Speichern\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(\"PROZESS ABGESCHLOSSEN\")\n",
        "    print(f\"Tabelle gespeichert: {csv_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"CSV nicht gefunden.\")"
      ],
      "metadata": {
        "id": "CX4zhHlQUvAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "links = [\n",
        "    \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp585/wc2.1_30s_tmax_MPI-ESM1-2-HR_ssp585_2081-2100.tif\",\n",
        "    \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp585/wc2.1_30s_tmin_MPI-ESM1-2-HR_ssp585_2081-2100.tif\",\n",
        "    \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp126/wc2.1_30s_tmax_MPI-ESM1-2-HR_ssp126_2081-2100.tif\",\n",
        "    \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp126/wc2.1_30s_tmin_MPI-ESM1-2-HR_ssp126_2081-2100.tif\"\n",
        "]\n",
        "\n",
        "print(\"Starte Link-Test...\\n\")\n",
        "\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "for url in links:\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    try:\n",
        "        # head() fragt nur nach dem Status, lädt keine Daten\n",
        "        r = requests.head(url, headers=headers, timeout=10)\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            # Wenn Datei da ist, schauen wir auf die Größe (Content-Length)\n",
        "            size_mb = int(r.headers.get('content-length', 0)) / (1024 * 1024)\n",
        "            print(f\"EXISTIERT: {filename}\")\n",
        "            print(f\"   Größe: {size_mb:.2f} MB\")\n",
        "        else:\n",
        "            print(f\"FEHLER {r.status_code}: {filename} nicht gefunden.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Verbindungsproblem bei {filename}: {e}\")\n",
        "\n",
        "print(\"Test beendet.\")"
      ],
      "metadata": {
        "id": "Axa5u_1dX3fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "temp_dir = '/content/temp_calc_final'\n",
        "\n",
        "if not os.path.exists(temp_dir):\n",
        "    os.makedirs(temp_dir)\n",
        "\n",
        "# Bounding Box Südtirol\n",
        "bbox = box(10.3, 46.2, 12.5, 47.1)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "data_links = {\n",
        "    \"SSP585\": {\n",
        "        \"tmax\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp585/wc2.1_30s_tmax_MPI-ESM1-2-HR_ssp585_2081-2100.tif\",\n",
        "        \"tmin\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp585/wc2.1_30s_tmin_MPI-ESM1-2-HR_ssp585_2081-2100.tif\"\n",
        "    },\n",
        "    \"SSP126\": {\n",
        "        \"tmax\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp126/wc2.1_30s_tmax_MPI-ESM1-2-HR_ssp126_2081-2100.tif\",\n",
        "        \"tmin\": \"https://geodata.ucdavis.edu/cmip6/30s/MPI-ESM1-2-HR/ssp126/wc2.1_30s_tmin_MPI-ESM1-2-HR_ssp126_2081-2100.tif\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Funktion: Große Datei laden, zuschneiden, löschen\n",
        "def process_huge_tif(url, scenario, var_type):\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    local_big_path = os.path.join(temp_dir, filename)\n",
        "    local_crop_path = os.path.join(temp_dir, f\"CROP_{scenario}_{var_type}.tif\")\n",
        "\n",
        "    # Prüfen, ob Crop schon da ist\n",
        "    if os.path.exists(local_crop_path):\n",
        "        print(f\"  -> Crop gefunden: {local_crop_path}\")\n",
        "        return local_crop_path\n",
        "\n",
        "    print(f\"\\nStarte Download: {filename} (ca. 4.9 GB)\")\n",
        "\n",
        "    # Streaming Download mit Requests\n",
        "    try:\n",
        "        with requests.get(url, stream=True, timeout=120) as r:\n",
        "            r.raise_for_status()\n",
        "            total_size = int(r.headers.get('content-length', 0))\n",
        "            downloaded = 0\n",
        "\n",
        "            with open(local_big_path, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=1024*1024): # 1MB Chunks\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "                        downloaded += len(chunk)\n",
        "                        # Fortschrittsanzeige\n",
        "                        if downloaded % (500 * 1024 * 1024) < 1050000:\n",
        "                            gb = downloaded / (1024**3)\n",
        "                            print(f\"     ... {gb:.2f} GB geladen\", end='\\r')\n",
        "\n",
        "        print(\"Download fertig. Schneide Südtirol aus...\")\n",
        "\n",
        "        # Zuschneiden\n",
        "        with rasterio.open(local_big_path) as src:\n",
        "            # Alle Bänder (12 Monate)\n",
        "            out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "            out_meta = src.meta.copy()\n",
        "\n",
        "            # Update Metadata für den Crop\n",
        "            out_meta.update({\n",
        "                \"driver\": \"GTiff\",\n",
        "                \"height\": out_image.shape[1],\n",
        "                \"width\": out_image.shape[2],\n",
        "                \"transform\": out_transform\n",
        "            })\n",
        "\n",
        "            # Crop speichern\n",
        "            with rasterio.open(local_crop_path, \"w\", **out_meta) as dest:\n",
        "                dest.write(out_image)\n",
        "\n",
        "        print(f\"  -> Crop gespeichert. Lösche große Datei...\")\n",
        "        os.remove(local_big_path)\n",
        "        return local_crop_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFEHLER bei {filename}: {e}\")\n",
        "        if os.path.exists(local_big_path): os.remove(local_big_path)\n",
        "        return None\n",
        "\n",
        "if os.path.exists(csv_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    # Koordinaten vorbereiten\n",
        "    coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "    print(f\"Verarbeite Daten für {len(df)} Punkte...\")\n",
        "\n",
        "    for scenario, types in data_links.items():\n",
        "        print(f\"\\n=== SZENARIO {scenario} ===\")\n",
        "\n",
        "        # 1. TMAX verarbeiten\n",
        "        crop_tmax = process_huge_tif(types['tmax'], scenario, 'tmax')\n",
        "        if not crop_tmax: continue # Abbruch wenn Download fehlschlagt\n",
        "\n",
        "        # 2. TMIN verarbeiten\n",
        "        crop_tmin = process_huge_tif(types['tmin'], scenario, 'tmin')\n",
        "        if not crop_tmin: continue\n",
        "\n",
        "        # 3. Berechnen\n",
        "        print(f\"Berechne BIO Variablen für {scenario}...\")\n",
        "\n",
        "        with rasterio.open(crop_tmax) as src_max:\n",
        "            tmax_data = src_max.read() # Shape: (12, H, W)\n",
        "\n",
        "        with rasterio.open(crop_tmin) as src_min:\n",
        "            tmin_data = src_min.read() # Shape: (12, H, W)\n",
        "\n",
        "        # BIO5: Max Temp of Warmest Month (Maximum über alle 12 Tmax-Monate)\n",
        "        bio5_grid = np.max(tmax_data, axis=0)\n",
        "\n",
        "        # BIO6: Min Temp of Coldest Month (Minimum über alle 12 Tmin-Monate)\n",
        "        bio6_grid = np.min(tmin_data, axis=0)\n",
        "\n",
        "        # BIO1: Annual Mean Temp (Mittelwert der monatlichen Mittelwerte)\n",
        "        # Monthly Mean = (Tmax + Tmin) / 2\n",
        "        monthly_means = (tmax_data + tmin_data) / 2.0\n",
        "        bio1_grid = np.mean(monthly_means, axis=0)\n",
        "\n",
        "        results = {\n",
        "            f\"BIO01_2100_{scenario}_Mean\": bio1_grid,\n",
        "            f\"BIO05_2100_{scenario}_Max\": bio5_grid,\n",
        "            f\"BIO06_2100_{scenario}_Min\": bio6_grid\n",
        "        }\n",
        "\n",
        "        with rasterio.open(crop_tmax) as src:\n",
        "            meta = src.meta.copy()\n",
        "            meta.update(count=1)\n",
        "\n",
        "        for col_name, grid in results.items():\n",
        "            temp_res_path = os.path.join(temp_dir, \"temp_res.tif\")\n",
        "            with rasterio.open(temp_res_path, 'w', **meta) as dst:\n",
        "                dst.write(grid, 1)\n",
        "\n",
        "            with rasterio.open(temp_res_path) as res_src:\n",
        "                vals = [x[0] for x in res_src.sample(coords)]\n",
        "                df[col_name] = vals\n",
        "                print(f\"  -> {col_name} eingetragen.\")\n",
        "\n",
        "            os.remove(temp_res_path)\n",
        "\n",
        "\n",
        "    # Speichern\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(\"FERTIG!\")\n",
        "else:\n",
        "    print(\"Fehler\")"
      ],
      "metadata": {
        "id": "d_vpybZ2YMy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import math\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_COMPLETE.csv'\n",
        "# Zukunfts-Datei\n",
        "proj_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_PROJEKTION_2100.csv'\n",
        "\n",
        "temp_dir = '/content/temp_topo'\n",
        "if not os.path.exists(temp_dir): os.makedirs(temp_dir)\n",
        "\n",
        "# Bounding Box Südtirol\n",
        "bbox = box(10.0, 46.0, 13.0, 47.5)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "# Elevation\n",
        "url = \"https://geodata.ucdavis.edu/climate/worldclim/2_1/base/wc2.1_30s_elev.zip\"\n",
        "zip_path = f\"{temp_dir}/elev.zip\"\n",
        "\n",
        "print(\"1. Lade Höhenmodell (WorldClim/SRTM)...\")\n",
        "if not os.path.exists(zip_path):\n",
        "    os.system(f\"wget -q -c {url} -O {zip_path}\")\n",
        "\n",
        "def calculate_slope_and_elevation(csv_path, elev_tif_path):\n",
        "    \"\"\"Liest Elevation und berechnet Slope (Grad) für eine CSV.\"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "\n",
        "    with rasterio.open(elev_tif_path) as src:\n",
        "        # Elevation auslesen\n",
        "        df['Elevation'] = [x[0] for x in src.sample(coords)]\n",
        "\n",
        "        # Slope Berechnung\n",
        "        out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "        data = out_image[0].astype('float32')\n",
        "\n",
        "        # Pixelgröße in Grad (aus Transform)\n",
        "        res_x = out_transform[0] # z.B. 0.008333\n",
        "        res_y = -out_transform[4] # z.B. 0.008333\n",
        "\n",
        "        # Umrechnung Grad -> Meter (bei ca. 46.5 Grad Breite)\n",
        "        # 1 Grad Latitude ~= 111132 Meter\n",
        "        # 1 Grad Longitude ~= 111132 * cos(lat) Meter\n",
        "        lat_mean = 46.5 * (math.pi / 180)\n",
        "        scale_x = 111132 * math.cos(lat_mean) * res_x\n",
        "        scale_y = 111132 * res_y\n",
        "\n",
        "        # Gradienten berechnen (np.gradient gibt Differenz pro Pixel)\n",
        "        dy, dx = np.gradient(data)\n",
        "\n",
        "        # Gradienten in Meter umrechnen (Höhenänderung pro Meter Distanz)\n",
        "        # dx ist Änderung pro Spalte, dy pro Zeile\n",
        "        slope_rad = np.arctan(np.sqrt((dx/scale_x)**2 + (dy/scale_y)**2))\n",
        "        slope_deg = np.degrees(slope_rad)\n",
        "\n",
        "        # Slope als temporäres TIF speichern, um zu samplen (genauer als Index-Matching)\n",
        "        meta = src.meta.copy()\n",
        "        meta.update({\n",
        "            \"driver\": \"GTiff\",\n",
        "            \"height\": data.shape[0],\n",
        "            \"width\": data.shape[1],\n",
        "            \"transform\": out_transform\n",
        "        })\n",
        "\n",
        "        slope_tif = f\"{temp_dir}/temp_slope.tif\"\n",
        "        with rasterio.open(slope_tif, 'w', **meta) as dst:\n",
        "            dst.write(slope_deg, 1)\n",
        "\n",
        "        with rasterio.open(slope_tif) as s_src:\n",
        "            df['Slope'] = [x[0] for x in s_src.sample(coords)]\n",
        "\n",
        "    return df\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "    tif_name = [f for f in z.namelist() if f.endswith('.tif')][0]\n",
        "    z.extract(tif_name, path=temp_dir)\n",
        "    elev_tif_full = f\"{temp_dir}/{tif_name}\"\n",
        "\n",
        "    # 1. Trainingsdaten aktualisieren\n",
        "    if os.path.exists(train_csv):\n",
        "        print(f\"Aktualisiere Training ({train_csv})...\")\n",
        "        df_train = calculate_slope_and_elevation(train_csv, elev_tif_full)\n",
        "        df_train.to_csv(train_csv, index=False)\n",
        "        print(\"  -> Elevation & Slope (Grad) eingefügt.\")\n",
        "\n",
        "    # 2. Zukunftsdaten aktualisieren\n",
        "    if os.path.exists(proj_csv):\n",
        "        print(f\"Aktualisiere Zukunft ({proj_csv})...\")\n",
        "        df_proj = calculate_slope_and_elevation(proj_csv, elev_tif_full)\n",
        "\n",
        "        # Spalten-Mapping für Zukunft (Vorbereitung Prediction)\n",
        "        # Damit der Random Forest die Spalten wiedererkennt\n",
        "        rename_map_126 = {\n",
        "            'BIO01_2100_SSP126_Mean': 'BIO01_Historical_Mean',\n",
        "            'BIO05_2100_SSP126_Max':  'BIO05_Historical_Max',\n",
        "            'BIO06_2100_SSP126_Min':  'BIO06_Historical_Min',\n",
        "            'BIO12_2100_SSP126':      'BIO12_Historical_Prec',\n",
        "            'BIO13_2100_SSP126':      'BIO13_Historical_Prec',\n",
        "            'BIO15_2100_SSP126':      'BIO15_Historical_Prec'\n",
        "        }\n",
        "\n",
        "        rename_map_585 = {\n",
        "            'BIO01_2100_SSP585_Mean': 'BIO01_Historical_Mean',\n",
        "            'BIO05_2100_SSP585_Max':  'BIO05_Historical_Max',\n",
        "            'BIO06_2100_SSP585_Min':  'BIO06_Historical_Min',\n",
        "            'BIO12_2100_SSP585':      'BIO12_Historical_Prec',\n",
        "            'BIO13_2100_SSP585':      'BIO13_Historical_Prec',\n",
        "            'BIO15_2100_SSP585':      'BIO15_Historical_Prec'\n",
        "        }\n",
        "\n",
        "        df_proj.to_csv(proj_csv, index=False)\n",
        "\n",
        "        # SSP126\n",
        "        df_126 = df_proj.copy().rename(columns=rename_map_126)\n",
        "        cols_126 = ['Latitude', 'Longitude', 'Elevation', 'Slope'] + list(rename_map_126.values())\n",
        "        # Nur behalten was da ist\n",
        "        df_126 = df_126[[c for c in cols_126 if c in df_126.columns]]\n",
        "        df_126.to_csv('/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP126_READY.csv', index=False)\n",
        "\n",
        "        # SSP585\n",
        "        df_585 = df_proj.copy().rename(columns=rename_map_585)\n",
        "        cols_585 = ['Latitude', 'Longitude', 'Elevation', 'Slope'] + list(rename_map_585.values())\n",
        "        df_585 = df_585[[c for c in cols_585 if c in df_585.columns]]\n",
        "        df_585.to_csv('/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP585_READY.csv', index=False)\n",
        "\n",
        "        print(\"  -> Elevation & Slope eingefügt.\")\n",
        "        print(\"  -> Prediction-Dateien (SSP126 & SSP585) erstellt.\")\n",
        "\n",
        "print(\"\\nFERTIG!\")"
      ],
      "metadata": {
        "id": "GfG4dPx-ho92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "orig_train_path = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_COMPLETE.csv'\n",
        "pred_126_path = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP126_READY.csv'\n",
        "pred_585_path = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP585_READY.csv'\n",
        "\n",
        "clean_train_output = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_CLEAN.csv'\n",
        "result_126 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP126.csv'\n",
        "result_585 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP585.csv'\n",
        "\n",
        "# Features, die das Modell nutzen soll\n",
        "features = [\n",
        "    'Latitude', 'Longitude', 'Elevation', 'Slope',\n",
        "    'BIO01_Historical_Mean', 'BIO05_Historical_Max', 'BIO06_Historical_Min',\n",
        "    'BIO12_Historical_Prec', 'BIO13_Historical_Prec', 'BIO15_Historical_Prec'\n",
        "]\n",
        "\n",
        "\n",
        "if not pd.io.common.file_exists(orig_train_path):\n",
        "    sys.exit(f\"Fehler: Datei nicht gefunden {orig_train_path}\")\n",
        "\n",
        "df = pd.read_csv(orig_train_path)\n",
        "\n",
        "# 1. Zielvariable erstellen (Text -> 0/1)\n",
        "# Alles ist Gefahr (1), außer es steht explizit \"No Rutschung\" da\n",
        "def map_risk(val):\n",
        "    text = str(val).strip()\n",
        "    if text == 'No Rutschung':\n",
        "        return 0 # Sicher\n",
        "    return 1 # Gefahr (Mure, Gleitung, etc.)\n",
        "\n",
        "df['Target'] = df['MOVEMENT_D'].apply(map_risk)\n",
        "\n",
        "counts = df['Target'].value_counts()\n",
        "print(f\"Verteilung der Klassen (0=Sicher, 1=Gefahr):\\n{counts}\")\n",
        "\n",
        "if 0 not in counts:\n",
        "    sys.exit(\"Keine 'No Rutschung' gefunden.\")\n",
        "\n",
        "# 2. Dings erstellen (Nur Features + Target)\n",
        "# ohne Datum, UUID und Rainfall_7d\n",
        "df_clean = df[features + ['Target']].copy()\n",
        "\n",
        "# NaNs in Features (z.B. fehlender Slope) mit 0 füllen\n",
        "df_clean[features] = df_clean[features].fillna(0)\n",
        "\n",
        "# Speichern\n",
        "df_clean.to_csv(clean_train_output, index=False)\n",
        "print(f\"Trainingsdatei gespeichert: {clean_train_output}\")\n",
        "print(f\"   (Enthält nur noch: {list(df_clean.columns)})\")\n",
        "\n",
        "\n",
        "print(\"\\n SCHRITT 2: TRAINING (RANDOM FOREST)\")\n",
        "\n",
        "X = df_clean[features]\n",
        "y = df_clean['Target']\n",
        "\n",
        "# Split: 80% Training, 20% Testen\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Modell initialisieren (300 Bäume)\n",
        "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Wie gut ist das Modell?\n",
        "y_pred = rf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"MODELL GENAUIGKEIT: {acc*100:.2f}%\")\n",
        "\n",
        "print(\"\\nWas sind die wichtigsten Treiber für Rutschungen?\")\n",
        "importances = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)\n",
        "print(importances.head(5))\n",
        "\n",
        "\n",
        "print(\"\\nSCHRITT 3: PROGNOSE 2100\")\n",
        "\n",
        "def predict_scenario(input_csv, output_csv, name):\n",
        "    print(f\"Berechne Karte für {name}...\")\n",
        "\n",
        "    if not pd.io.common.file_exists(input_csv):\n",
        "        print(f\"Fehler: Input fehlt {input_csv}\")\n",
        "        return\n",
        "\n",
        "    df_future = pd.read_csv(input_csv)\n",
        "\n",
        "    # Sicherstellen, dass Slope/Elevation da sind (fillna 0 falls Lücken)\n",
        "    X_future = df_future[features].fillna(0)\n",
        "\n",
        "    # Wahrscheinlichkeit berechnen (0.0 bis 1.0)\n",
        "    probs = rf.predict_proba(X_future)[:, 1]\n",
        "\n",
        "    # Ins CSV schreiben\n",
        "    df_future['Landslide_Probability'] = probs\n",
        "\n",
        "    # Eine lesbare Klasse dazu\n",
        "    df_future['Risk_Class'] = df_future['Landslide_Probability'].apply(\n",
        "        lambda x: 'HOCH' if x >= 0.7 else ('MITTEL' if x >= 0.3 else 'NIEDRIG')\n",
        "    )\n",
        "\n",
        "    df_future.to_csv(output_csv, index=False)\n",
        "    print(f\"Karte erstellt: {output_csv}\")\n",
        "\n",
        "# Ausführen\n",
        "predict_scenario(pred_126_path, result_126, \"SSP126 (Optimistisch)\")\n",
        "predict_scenario(pred_585_path, result_585, \"SSP585 (Pessimistisch)\")\n",
        "\n",
        "print(\"fertig!\")"
      ],
      "metadata": {
        "id": "5c-CvuLTk2Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "clean_train_path = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_CLEAN.csv'\n",
        "result_126 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP126_PRUNED.csv'\n",
        "result_585 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP585_PRUNED.csv'\n",
        "pred_126_path = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP126_READY.csv'\n",
        "pred_585_path = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP585_READY.csv'\n",
        "\n",
        "# Features\n",
        "features = [\n",
        "    'Latitude', 'Longitude', 'Elevation', 'Slope',\n",
        "    'BIO01_Historical_Mean', 'BIO05_Historical_Max', 'BIO06_Historical_Min',\n",
        "    'BIO12_Historical_Prec', 'BIO13_Historical_Prec', 'BIO15_Historical_Prec'\n",
        "]\n",
        "\n",
        "# Daten laden\n",
        "df = pd.read_csv(clean_train_path)\n",
        "X = df[features].fillna(0)\n",
        "y = df['Target']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"1. OVERFITTING??\")\n",
        "# Das alte Modell (ungebremst)\n",
        "rf_old = RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42)\n",
        "rf_old.fit(X_train, y_train)\n",
        "\n",
        "train_acc = rf_old.score(X_train, y_train)\n",
        "test_acc = rf_old.score(X_test, y_test)\n",
        "\n",
        "print(f\"Altes Modell - Training Genauigkeit: {train_acc*100:.2f}%\")\n",
        "print(f\"Altes Modell - Test Genauigkeit:     {test_acc*100:.2f}%\")\n",
        "diff = train_acc - test_acc\n",
        "print(f\"-> Unterschied: {diff*100:.2f} Prozentpunkte\")\n",
        "\n",
        "if diff > 0.10:\n",
        "    print(\"Achtung: Hohes Overfitting! Modell lernt auswendig.\")\n",
        "else:\n",
        "    print(\"Info: Overfitting hält sich in Grenzen.\")\n",
        "\n",
        "\n",
        "print(\"\\n 2.: MODELL MIT PRUNING\")\n",
        "# Wir setzen Constraints\n",
        "rf_pruned = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=10,        # Nicht tiefer als 10 Ebenen\n",
        "    min_samples_leaf=4,  # Jedes Blatt muss mind. 4 Fälle abdecken (verhindert Ausreißer-Regeln)\n",
        "    max_features='sqrt', # Standard, aber gut zu explizieren\n",
        "    random_state=42\n",
        ")\n",
        "rf_pruned.fit(X_train, y_train)\n",
        "\n",
        "train_acc_new = rf_pruned.score(X_train, y_train)\n",
        "test_acc_new = rf_pruned.score(X_test, y_test)\n",
        "\n",
        "print(f\"Neues Modell - Training Genauigkeit: {train_acc_new*100:.2f}%\")\n",
        "print(f\"Neues Modell - Test Genauigkeit:     {test_acc_new*100:.2f}%\")\n",
        "\n",
        "print(\"\\n--- 3. NEUE KARTEN ERSTELLEN ---\")\n",
        "# Funktion für Vorhersage\n",
        "def predict_scenario(input_csv, output_csv, name):\n",
        "    if not pd.io.common.file_exists(input_csv): return\n",
        "    df_future = pd.read_csv(input_csv)\n",
        "    X_fut = df_future[features].fillna(0)\n",
        "\n",
        "    # Wahrscheinlichkeiten\n",
        "    probs = rf_pruned.predict_proba(X_fut)[:, 1]\n",
        "    df_future['Landslide_Probability'] = probs\n",
        "\n",
        "    # Klasse\n",
        "    df_future['Risk_Class'] = df_future['Landslide_Probability'].apply(\n",
        "        lambda x: 'HOCH' if x >= 0.7 else ('MITTEL' if x >= 0.3 else 'NIEDRIG')\n",
        "    )\n",
        "\n",
        "    df_future.to_csv(output_csv, index=False)\n",
        "    print(f\"Pruned Karte gespeichert: {output_csv}\")\n",
        "\n",
        "predict_scenario(pred_126_path, result_126, \"SSP126_Pruned\")\n",
        "predict_scenario(pred_585_path, result_585, \"SSP585_Pruned\")"
      ],
      "metadata": {
        "id": "ok6CXkvEmLTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "file_126 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP126_PRUNED.csv'\n",
        "file_585 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP585_PRUNED.csv'\n",
        "\n",
        "df_126 = pd.read_csv(file_126)\n",
        "df_585 = pd.read_csv(file_585)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
        "cmap = \"RdYlGn_r\" # Grün=Sicher, Rot=Gefahr\n",
        "\n",
        "def plot_map(ax, df, title):\n",
        "    # Scatter Plot\n",
        "    sc = ax.scatter(\n",
        "        df['Longitude'],\n",
        "        df['Latitude'],\n",
        "        c=df['Landslide_Probability'],\n",
        "        cmap=cmap,\n",
        "        s=20,\n",
        "        alpha=0.8,\n",
        "        vmin=0, vmax=1\n",
        "    )\n",
        "\n",
        "    # Hintergrund (grob)\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    ax.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "    # Statistik direkt im Plot\n",
        "    n_high = df[df['Landslide_Probability'] > 0.7].shape[0]\n",
        "    n_total = df.shape[0]\n",
        "    percent = (n_high / n_total) * 100\n",
        "    ax.text(0.05, 0.05, f\"High Risk (>70%): {n_high} Punkte ({percent:.1f}%)\",\n",
        "            transform=ax.transAxes, fontsize=12,\n",
        "            bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "    return sc\n",
        "\n",
        "# Karte 1\n",
        "sc1 = plot_map(axes[0], df_126, \"Szenario SSP126 (Optimistisch)\\n(Pruned Model)\")\n",
        "\n",
        "# Karte 2\n",
        "sc2 = plot_map(axes[1], df_585, \"Szenario SSP585 (Pessimistisch)\\n(Pruned Model)\")\n",
        "\n",
        "# Legende\n",
        "cbar = fig.colorbar(sc1, ax=axes.ravel().tolist(), pad=0.02)\n",
        "cbar.set_label(\"Rutschungswahrscheinlichkeit (0.0 - 1.0)\", fontsize=14)\n",
        "\n",
        "plt.suptitle(\"Vergleich der Erdrutsch-Gefahr Südtirol 2100\", fontsize=22)\n",
        "plt.show()\n",
        "\n",
        "# ZAHLEN\n",
        "high_126 = df_126[df_126['Landslide_Probability'] > 0.7].shape[0]\n",
        "high_585 = df_585[df_585['Landslide_Probability'] > 0.7].shape[0]\n",
        "\n",
        "print(f\"\\n DAS ERGEBNIS\")\n",
        "print(f\"Hochrisiko-Punkte im 'Best Case' (SSP126):  {high_126}\")\n",
        "print(f\"Hochrisiko-Punkte im 'Worst Case' (SSP585): {high_585}\")\n",
        "print(f\"-> Differenz: {high_585 - high_126} zusätzliche Gefahrenstellen durch extremen Klimawandel.\")"
      ],
      "metadata": {
        "id": "HTsUIoGSmwzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "path_126 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP126_PRUNED.csv'\n",
        "path_585 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP585_PRUNED.csv'\n",
        "\n",
        "df_126 = pd.read_csv(path_126)\n",
        "df_585 = pd.read_csv(path_585)\n",
        "\n",
        "# Spalte \"Szenario\" hinzufügen, um sie gleich gemeinsam zu plotten\n",
        "df_126['Szenario'] = 'SSP126 (Optimistisch)'\n",
        "df_585['Szenario'] = 'SSP585 (Pessimistisch)'\n",
        "\n",
        "df_all = pd.concat([df_126, df_585])\n",
        "\n",
        "# 1. DAS HISTOGRAMM\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(\n",
        "    data=df_all,\n",
        "    x='Landslide_Probability',\n",
        "    hue='Szenario',\n",
        "    element='step',\n",
        "    stat='percent',\n",
        "    common_norm=False,\n",
        "    palette=['green', 'red'], # Grün für 126, Rot für 585 (als Unterscheidung)\n",
        "    kde=True\n",
        ")\n",
        "plt.axvline(0.3, color='orange', linestyle='--', alpha=0.5, label='Grenze Gelb (30%)')\n",
        "plt.axvline(0.7, color='red', linestyle='--', alpha=0.5, label='Grenze Rot (70%)')\n",
        "plt.title('Verschiebung der Risiko-Wahrscheinlichkeiten (Verteilung)', fontsize=16)\n",
        "plt.xlabel('Wahrscheinlichkeit für Rutschung (0.0 = Sicher, 1.0 = Gefahr)')\n",
        "plt.ylabel('Anteil der Punkte (%)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 2. VERGLEICH (Zahlen)\n",
        "def get_category(prob):\n",
        "    if prob < 0.3: return '1. Niedrig (Grün)'\n",
        "    if prob < 0.7: return '2. Mittel (Gelb)'\n",
        "    return '3. Hoch (Rot)'\n",
        "\n",
        "df_126['Kategorie'] = df_126['Landslide_Probability'].apply(get_category)\n",
        "df_585['Kategorie'] = df_585['Landslide_Probability'].apply(get_category)\n",
        "\n",
        "# Zählen\n",
        "count_126 = df_126['Kategorie'].value_counts().sort_index()\n",
        "count_585 = df_585['Kategorie'].value_counts().sort_index()\n",
        "\n",
        "# DataFrame für den Plot bauen\n",
        "comparison = pd.DataFrame({\n",
        "    'SSP126': count_126,\n",
        "    'SSP585': count_585\n",
        "}).fillna(0) # Falls eine Kategorie 0 ist\n",
        "\n",
        "print(\"\\n DETAILLIERTE ZAHLEN\")\n",
        "print(comparison)\n",
        "\n",
        "# Balkendiagramm\n",
        "comparison.plot(kind='bar', figsize=(10, 6), color=['#66c2a5', '#fc8d62'])\n",
        "plt.title('Anzahl Punkte pro Risiko-Klasse', fontsize=16)\n",
        "plt.ylabel('Anzahl Punkte')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# 3. analyse der gelben/nicht-nur-roten punkte, weil Ergebnis vorher leicht komishc....\n",
        "diff_yellow = comparison.loc['2. Mittel (Gelb)', 'SSP585'] - comparison.loc['2. Mittel (Gelb)', 'SSP126']\n",
        "print(f\"\\nVeränderung der gelben Punkte (Mittel): {diff_yellow:+.0f}\")\n",
        "\n",
        "if diff_yellow > 0:\n",
        "    print(\"-> Viele rote Punkte sind nicht 'sicher' geworden, sondern nur 'unsicherer' (Gelb).\")\n",
        "    print(\"   Das Risiko ist also nicht weg, es ist nur diffuser geworden.\")\n",
        "else:\n",
        "    print(\"-> Die gelben Punkte sind auch weniger geworden oder gleich geblieben.\")\n",
        "    print(\"   tatsächlich weniger risiko (Austrocknung?)\")"
      ],
      "metadata": {
        "id": "qu27kwRaoBFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "path_126 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP126_PRUNED.csv'\n",
        "path_585 = '/content/drive/MyDrive/testNaturgefahren/RESULT_Risk_Map_2100_SSP585_PRUNED.csv'\n",
        "\n",
        "df_126 = pd.read_csv(path_126)\n",
        "df_585 = pd.read_csv(path_585)\n",
        "\n",
        "# Worst Case MINUS Best Case\n",
        "df_126['Diff'] = df_585['Landslide_Probability'] - df_126['Landslide_Probability']\n",
        "\n",
        "# Plotten\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Farbskala: Rot = Risiko steigt, Blau = Risiko sinkt\n",
        "cmap = \"seismic\"\n",
        "\n",
        "# Scatterplot\n",
        "sc = plt.scatter(\n",
        "    df_126['Longitude'],\n",
        "    df_126['Latitude'],\n",
        "    c=df_126['Diff'],\n",
        "    cmap=cmap,\n",
        "    s=25,\n",
        "    alpha=0.8,\n",
        "    vmin=-0.5, vmax=0.5 # besserer Kontrast\n",
        ")\n",
        "\n",
        "cbar = plt.colorbar(sc)\n",
        "cbar.set_label(\"Veränderung der Wahrscheinlichkeit (SSP585 - SSP126)\", fontsize=12)\n",
        "\n",
        "plt.title(\"Wo wird es gefährlicher? (Differenzkarte)\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Text-Hinweis ins Bild\n",
        "plt.text(10.5, 46.1, \"ROT = Risiko nimmt im 'Worst Case' ZU\\nBLAU = Risiko nimmt im 'Worst Case' AB\",\n",
        "         fontsize=12, bbox=dict(facecolor='white', alpha=0.9))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Kurze Info dazu\n",
        "print(\"STATISTIK DER VERÄNDERUNG\")\n",
        "print(f\"Orte, an denen es gefährlicher wird (Diff > 0.1): {df_126[df_126['Diff'] > 0.1].shape[0]}\")\n",
        "print(f\"Orte, an denen es sicherer wird (Diff < -0.1):    {df_126[df_126['Diff'] < -0.1].shape[0]}\")"
      ],
      "metadata": {
        "id": "Rt0-AXunpywC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clean_train_path = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_CLEAN.csv'\n",
        "df = pd.read_csv(clean_train_path)\n",
        "\n",
        "# Features & Target\n",
        "features = [\n",
        "    'Latitude', 'Longitude', 'Elevation', 'Slope',\n",
        "    'BIO01_Historical_Mean', 'BIO05_Historical_Max', 'BIO06_Historical_Min',\n",
        "    'BIO12_Historical_Prec', 'BIO13_Historical_Prec', 'BIO15_Historical_Prec'\n",
        "]\n",
        "\n",
        "X = df[features].fillna(0)\n",
        "y = df['Target']\n",
        "\n",
        "# Split (gleicher Random State wie beim Training)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# MODELL (PRUNED)\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=4, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage auf den Test-Daten\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Koordinaten der Test-Punkte\n",
        "plot_df = X_test[['Longitude', 'Latitude']].copy()\n",
        "plot_df['Actual'] = y_test\n",
        "plot_df['Predicted'] = y_pred\n",
        "\n",
        "# Kategorien bestimmen\n",
        "def get_category(row):\n",
        "    if row['Actual'] == 1 and row['Predicted'] == 1:\n",
        "        return 'TP' # Correct Landslide (Richtig erkannt Rutsch)\n",
        "    elif row['Actual'] == 0 and row['Predicted'] == 0:\n",
        "        return 'TN' # Correct No-Slide (Richtig erkannt kein Rutsch)\n",
        "    elif row['Actual'] == 0 and row['Predicted'] == 1:\n",
        "        return 'FP' # False Alarm (Fehlalarm)\n",
        "    elif row['Actual'] == 1 and row['Predicted'] == 0:\n",
        "        return 'FN' # Missed Landslide (Übersehen!)\n",
        "    return 'Error'\n",
        "\n",
        "plot_df['Category'] = plot_df.apply(get_category, axis=1)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# 1. Correct No-Slide (TN) -> Orange Punkte\n",
        "tn = plot_df[plot_df['Category'] == 'TN']\n",
        "plt.scatter(tn['Longitude'], tn['Latitude'], c='orange', s=30, alpha=0.6, label='Korrekt: Kein Rutsch (TN)')\n",
        "\n",
        "# 2. False Alarm (FP) -> Lila Punkte\n",
        "fp = plot_df[plot_df['Category'] == 'FP']\n",
        "plt.scatter(fp['Longitude'], fp['Latitude'], c='purple', s=40, marker='o', label='Falscher Alarm (FP)')\n",
        "\n",
        "# 3. Correct Landslide (TP) -> Grüne Sterne\n",
        "tp = plot_df[plot_df['Category'] == 'TP']\n",
        "plt.scatter(tp['Longitude'], tp['Latitude'], c='darkgreen', s=150, marker='*', edgecolors='black', label='Korrekt: Rutschung (TP)')\n",
        "\n",
        "# 4. Missed Landslide (FN) -> Rotes Kreuz\n",
        "fn = plot_df[plot_df['Category'] == 'FN']\n",
        "plt.scatter(fn['Longitude'], fn['Latitude'], c='red', s=100, marker='x', linewidth=2, label='Übersehener Rutsch (FN)')\n",
        "\n",
        "plt.title(\"Modell-Evaluation: Wo macht die KI Fehler?\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.legend(loc='upper right', frameon=True, fontsize=11)\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Statistik ins Bild schreiben\n",
        "stat_text = (\n",
        "    f\"Test-Daten: {len(plot_df)} Punkte\\n\"\n",
        "    f\"Genauigkeit: {rf.score(X_test, y_test)*100:.1f}%\\n\"\n",
        "    f\"Übersehen (FN): {len(fn)}\"\n",
        ")\n",
        "plt.text(0.02, 0.02, stat_text, transform=plt.gca().transAxes,\n",
        "         bbox=dict(facecolor='white', alpha=0.8), fontsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IhM3ARllqk5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import geopandas as gpd\n",
        "#das hat nicht geklappt, weil noch falsches shapefile?! ÄNDERN NEU VERSUCHEN\n",
        "clean_train_path = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_CLEAN.csv'\n",
        "\n",
        "shapefile_path = r'C:\\Users\\richt\\Desktop\\testNaturgefahrenOhneBuffer\\extent_UG\\UG.shp'\n",
        "# shapefile_path = '/content/drive/MyDrive/testNaturgefahren/UG.shp'\n",
        "\n",
        "df = pd.read_csv(clean_train_path)\n",
        "\n",
        "features = [\n",
        "    'Latitude', 'Longitude', 'Elevation', 'Slope',\n",
        "    'BIO01_Historical_Mean', 'BIO05_Historical_Max', 'BIO06_Historical_Min',\n",
        "    'BIO12_Historical_Prec', 'BIO13_Historical_Prec', 'BIO15_Historical_Prec'\n",
        "]\n",
        "X = df[features].fillna(0)\n",
        "y = df['Target']\n",
        "\n",
        "# Exakt gleicher Split wie beim Training\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# MODELL (PRUNED)\n",
        "rf = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=4, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy = rf.score(X_test, y_test)\n",
        "\n",
        "plot_df = X_test[['Longitude', 'Latitude']].copy()\n",
        "plot_df['Actual'] = y_test\n",
        "plot_df['Predicted'] = y_pred\n",
        "\n",
        "def get_category(row):\n",
        "    if row['Actual'] == 1 and row['Predicted'] == 1: return 'TP'\n",
        "    elif row['Actual'] == 0 and row['Predicted'] == 0: return 'TN'\n",
        "    elif row['Actual'] == 0 and row['Predicted'] == 1: return 'FP'\n",
        "    elif row['Actual'] == 1 and row['Predicted'] == 0: return 'FN'\n",
        "    return 'Error'\n",
        "\n",
        "plot_df['Category'] = plot_df.apply(get_category, axis=1)\n",
        "\n",
        "try:\n",
        "    shp = gpd.read_file(shapefile_path)\n",
        "    # Sicherstellen, dass das Shapefile im richtigen KOS ist (WGS84 für Lat/Lon)\n",
        "    if shp.crs != 'EPSG:4326':\n",
        "        shp = shp.to_crs('EPSG:4326')\n",
        "    shapefile_loaded = True\n",
        "except Exception as e:\n",
        "    print(f\"Fehler beim Laden des Shapefiles: {e}\")\n",
        "    shapefile_loaded = False\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "# 1. Shapefile plotten (als Hintergrund)\n",
        "if shapefile_loaded:\n",
        "    shp.plot(ax=ax, color='none', edgecolor='black', linewidth=1, zorder=1)\n",
        "\n",
        "# 2. Punkte plotten\n",
        "# TN (Orange)\n",
        "tn = plot_df[plot_df['Category'] == 'TN']\n",
        "ax.scatter(tn['Longitude'], tn['Latitude'], c='orange', s=30, alpha=0.7, label='Korrekt: Kein Rutsch (TN)', zorder=2)\n",
        "\n",
        "# FP (Lila)\n",
        "fp = plot_df[plot_df['Category'] == 'FP']\n",
        "ax.scatter(fp['Longitude'], fp['Latitude'], c='purple', s=40, marker='o', label='Falscher Alarm (FP)', zorder=2)\n",
        "\n",
        "# TP (Grüne Sterne)\n",
        "tp = plot_df[plot_df['Category'] == 'TP']\n",
        "ax.scatter(tp['Longitude'], tp['Latitude'], c='darkgreen', s=150, marker='*', edgecolors='black', label='Korrekt: Rutschung (TP)', zorder=3)\n",
        "\n",
        "# FN (Rote Kreuze)\n",
        "fn = plot_df[plot_df['Category'] == 'FN']\n",
        "ax.scatter(fn['Longitude'], fn['Latitude'], c='red', s=100, marker='x', linewidth=2, label='Übersehener Rutsch (FN)', zorder=3)\n",
        "\n",
        "# LAYOUT\n",
        "ax.set_title(\"Modell-Evaluation: Wo macht die KI Fehler? (mit Südtirol-Grenzen)\", fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel(\"Longitude\")\n",
        "ax.set_ylabel(\"Latitude\")\n",
        "ax.legend(loc='upper right', frameon=True, fontsize=11)\n",
        "ax.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Statistik-Box\n",
        "fn_count = len(fn)\n",
        "stat_text = (\n",
        "    f\"Test-Daten: {len(plot_df)} Punkte\\n\"\n",
        "    f\"Genauigkeit: {accuracy*100:.1f}%\\n\"\n",
        "    f\"Übersehen (FN): {fn_count}\"\n",
        ")\n",
        "ax.text(0.02, 0.02, stat_text, transform=ax.transAxes,\n",
        "         bbox=dict(facecolor='white', alpha=0.9, boxstyle='round,pad=0.5'), fontsize=12, zorder=4)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y9KzpyvGsKzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.mask import mask\n",
        "from shapely.geometry import box\n",
        "import geopandas as gpd\n",
        "import zipfile\n",
        "import os\n",
        "import math\n",
        "\n",
        "train_csv = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_CLEAN.csv'\n",
        "proj_csv_126 = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP126_READY.csv'\n",
        "proj_csv_585 = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP585_READY.csv'\n",
        "\n",
        "temp_dir = '/content/temp_topo'\n",
        "if not os.path.exists(temp_dir): os.makedirs(temp_dir)\n",
        "elev_zip = f\"{temp_dir}/elev.zip\"\n",
        "url = \"https://geodata.ucdavis.edu/climate/worldclim/2_1/base/wc2.1_30s_elev.zip\"\n",
        "\n",
        "if not os.path.exists(elev_zip):\n",
        "    print(\"Lade Elevation neu...\")\n",
        "    os.system(f\"wget -q -c {url} -O {elev_zip}\")\n",
        "\n",
        "# Entpacken\n",
        "with zipfile.ZipFile(elev_zip, 'r') as z:\n",
        "    tif_name = [f for f in z.namelist() if f.endswith('.tif')][0]\n",
        "    z.extract(tif_name, path=temp_dir)\n",
        "    elev_tif = f\"{temp_dir}/{tif_name}\"\n",
        "\n",
        "# Bounding Box Südtirol\n",
        "bbox = box(10.0, 46.0, 13.0, 47.5)\n",
        "geo = gpd.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
        "\n",
        "def add_aspect(csv_path):\n",
        "    print(f\"Bearbeite {os.path.basename(csv_path)}...\")\n",
        "    df = pd.read_csv(csv_path)\n",
        "    coords = [(row['Longitude'], row['Latitude']) for _, row in df.iterrows()]\n",
        "\n",
        "    with rasterio.open(elev_tif) as src:\n",
        "        out_image, out_transform = mask(src, geo.geometry, crop=True)\n",
        "        data = out_image[0].astype('float32')\n",
        "\n",
        "        # Gradienten berechnen (wie bei Slope)\n",
        "        res_x = out_transform[0]\n",
        "        res_y = -out_transform[4]\n",
        "        lat_mean = 46.5 * (math.pi / 180)\n",
        "        scale_x = 111132 * math.cos(lat_mean) * res_x\n",
        "        scale_y = 111132 * res_y\n",
        "\n",
        "        dy, dx = np.gradient(data)\n",
        "\n",
        "        # Aspect ist die Richtung des Gefälles (0-360 Grad)\n",
        "        # arctan2(dy, -dx) gibt Bogenmaß\n",
        "        aspect_rad = np.arctan2(-dx, dy) # Minus dx wegen Koordinatensystem-Besonderheiten bei Grids\n",
        "        aspect_deg = np.degrees(aspect_rad)\n",
        "\n",
        "        # Umrechnung: Norden=0, Osten=90...\n",
        "        # arctan2 gibt -180 bis 180. aber will 0 bis 360\n",
        "        aspect_deg = np.where(aspect_deg < 0, aspect_deg + 360, aspect_deg)\n",
        "\n",
        "        # Speichern & Samplen\n",
        "        meta = src.meta.copy()\n",
        "        meta.update({\"driver\": \"GTiff\", \"height\": data.shape[0], \"width\": data.shape[1], \"transform\": out_transform})\n",
        "\n",
        "        aspect_tif = f\"{temp_dir}/temp_aspect.tif\"\n",
        "        with rasterio.open(aspect_tif, 'w', **meta) as dst:\n",
        "            dst.write(aspect_deg, 1)\n",
        "\n",
        "        with rasterio.open(aspect_tif) as a_src:\n",
        "            df['Aspect'] = [x[0] for x in a_src.sample(coords)]\n",
        "\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(\" -> Aspect hinzugefügt.\")\n",
        "\n",
        "# Ausführen für alle 3 Dateien\n",
        "add_aspect(train_csv)\n",
        "add_aspect(proj_csv_126)\n",
        "add_aspect(proj_csv_585)\n",
        "\n",
        "print(\"\\nFertig! Jetzt weiß das Modell auch, ob der Hang nach Norden oder Süden zeigt.\")"
      ],
      "metadata": {
        "id": "zrnQnJkvuTJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "clean_train_path = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_CLEAN.csv'\n",
        "\n",
        "df = pd.read_csv(clean_train_path)\n",
        "\n",
        "# mit Aspect, aber ohne Lat/Lon\n",
        "features_physic = [\n",
        "    'Elevation',\n",
        "    'Slope',\n",
        "    'Aspect',  # neu\n",
        "    'BIO01_Historical_Mean',\n",
        "    'BIO05_Historical_Max',\n",
        "    'BIO06_Historical_Min',\n",
        "    'BIO12_Historical_Prec',\n",
        "    'BIO13_Historical_Prec',\n",
        "    'BIO15_Historical_Prec'\n",
        "]\n",
        "\n",
        "# Prüfen ob Aspect wirklich da ist (falls das vorige Skript geklappt hat)\n",
        "if 'Aspect' not in df.columns:\n",
        "    print(\"WARNUNG: 'Aspect' fehlt in der CSV! provisorisch mit 0 fpllen, damit der Test läuft.\")\n",
        "    df['Aspect'] = 0\n",
        "\n",
        "X = df[features_physic].fillna(0)\n",
        "y = df['Target']\n",
        "\n",
        "# Split (Gleicher Seed für Fairness)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TRAINING (PRUNED)\n",
        "print(\"Trainiere Modell (ohne Koordinaten)...\")\n",
        "rf_physic = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=4, random_state=42)\n",
        "rf_physic.fit(X_train, y_train)\n",
        "\n",
        "# ERGEBNISSE\n",
        "acc = rf_physic.score(X_test, y_test)\n",
        "\n",
        "print(f\"\\n TEST-ERGEBNIS\")\n",
        "print(f\"Genauigkeit ohne Lat/Lon: {acc*100:.2f}%\")\n",
        "# Zum Vergleich: Vorher waren es ca. 80.6%\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, rf_physic.predict(X_test)))\n",
        "\n",
        "print(\"WAS IST JETZT WICHTIG? (Feature Importance)\")\n",
        "importances = pd.Series(rf_physic.feature_importances_, index=features_physic).sort_values(ascending=False)\n",
        "print(importances)\n",
        "\n",
        "# Fazit\n",
        "if acc > 0.75:\n",
        "    print(\"\\n Das Modell funktioniert auch ohne Koordinaten. gut!\")\n",
        "elif acc > 0.70:\n",
        "    print(\"\\n Es hat etwas verloren, aber ist noch brauchbar.\")\n",
        "else:\n",
        "    print(\"\\n VORSICHT. Die Genauigkeit ist stark gesunken. Lat/Lon waren sehr wichtig.\")"
      ],
      "metadata": {
        "id": "Oav_K-SSu4nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "train_path = '/content/drive/MyDrive/testNaturgefahren/landslides_TRAINING_CLEAN.csv'\n",
        "pred_126 = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP126_READY.csv'\n",
        "pred_585 = '/content/drive/MyDrive/testNaturgefahren/PREDICT_SSP585_READY.csv'\n",
        "\n",
        "# Output\n",
        "res_126 = '/content/drive/MyDrive/testNaturgefahren/RESULT_FINAL_SSP126.csv'\n",
        "res_585 = '/content/drive/MyDrive/testNaturgefahren/RESULT_FINAL_SSP585.csv'\n",
        "\n",
        "# mit Aspect, aber ohne Lat/Lon\n",
        "features = [\n",
        "    'Elevation', 'Slope', 'Aspect',\n",
        "    'BIO01_Historical_Mean', 'BIO05_Historical_Max', 'BIO06_Historical_Min',\n",
        "    'BIO12_Historical_Prec', 'BIO13_Historical_Prec', 'BIO15_Historical_Prec'\n",
        "]\n",
        "\n",
        "print(\"1. Lade Daten & Trainiere Modell...\")\n",
        "df = pd.read_csv(train_path)\n",
        "\n",
        "# Aspect sicherstellen (falls NaN -> 0)\n",
        "df['Aspect'] = df.get('Aspect', 0)\n",
        "X = df[features].fillna(0)\n",
        "y = df['Target']\n",
        "\n",
        "# Finales Training alle Daten!!\n",
        "rf_final = RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=4, random_state=42)\n",
        "rf_final.fit(X, y)\n",
        "print(\"   -> Modell trainiert.\")\n",
        "\n",
        "# 2. PROGNOSE 2100\n",
        "def run_prediction(in_path, out_path, name):\n",
        "    print(f\"2. Berechne {name}...\")\n",
        "    df_fut = pd.read_csv(in_path)\n",
        "\n",
        "    if 'Aspect' not in df_fut.columns:\n",
        "        print(\"   Warnung: Aspect fehlt in Prediction-File. Setze auf 0.\")\n",
        "        df_fut['Aspect'] = 0\n",
        "\n",
        "    X_fut = df_fut[features].fillna(0)\n",
        "\n",
        "    # Wahrscheinlichkeit\n",
        "    probs = rf_final.predict_proba(X_fut)[:, 1]\n",
        "    df_fut['Landslide_Probability'] = probs\n",
        "\n",
        "    # Klassen\n",
        "    df_fut['Risk_Class'] = df_fut['Landslide_Probability'].apply(\n",
        "        lambda x: 'HOCH' if x >= 0.7 else ('MITTEL' if x >= 0.3 else 'NIEDRIG')\n",
        "    )\n",
        "\n",
        "    df_fut.to_csv(out_path, index=False)\n",
        "    print(f\"   -> Gespeichert: {out_path}\")\n",
        "\n",
        "run_prediction(pred_126, res_126, \"SSP126 (Optimistisch)\")\n",
        "run_prediction(pred_585, res_585, \"SSP585 (Pessimistisch)\")\n",
        "\n",
        "print(\"\\nFERTIG!\")"
      ],
      "metadata": {
        "id": "WC6VHCaGvkXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}